\section{Results}
\label{sec:results}

\subsection{Benchmarks}

For our test setup, we deployed our stack on an \textit{Intel NUC}, which is a fairly inexpensive
mini PC. With the following benchmarks we want to show what such an affordable machine is capable
of when coupled with other cheap IoT devices (e.g. Raspberry Pis).

\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|l|r|}
    \hline
    Name                     & Model              & Processor                                                                             & Memory              \\ \hline
    \whitelist{Intel NUC}    & \whitelist{8I5BEH} & \whitelist{Intel Core i5-8259U} @ \SI{2.30}{\giga\hertz}                              & \SI{16}{\giga\byte} \\ \hline
    \whitelist{Raspberry Pi} & 3 B+               & \whitelist{Broadcom BCM2837B0, 64-bit SoC} @ \SI{1.4}{\giga\hertz}                    & \SI{1}{\giga\byte}  \\ \hline
    Desktop PC               & â€“                  & \whitelist{Intel Core i9-7900X} @ \SI{4.7}{\giga\hertz}                               & \SI{64}{\giga\byte} \\ \hline
  \end{tabular}
  \caption{Hardware used for Benchmark}
  \label{tab:benchmark-hardware}
\end{table}

The specific hardware we used for benchmarking is listed in \autoref{tab:benchmark-hardware} above.
The desktop PC and the \textit{NUC} were both connected via \whitelist{ethernet} to a \SI{1}{\giga\bit} network
switch. The \textit{Raspberry Pi} was connected via WiFi to an access point connected to the same
switch. \autoref{tab:benchmark-network-speed} shows the link speed between the hardware components
as tested with \texttt{iperf3} \cite{iperf}.

\begin{table}[H]
  \centering
  \begin{tabular}{|l|r|}
    \hline
    Connection                                  & Speed                          \\ \hline
    \textit{NUC} $\leftrightarrow$ Desktop PC   & \SI{940}{\mega\bit\per\second} \\ \hline
    \textit{NUC} $\leftrightarrow$ Raspberry Pi & \SI{55}{\mega\bit\per\second}  \\ \hline
  \end{tabular}
  \caption{Link speed between hardware components}
  \label{tab:benchmark-network-speed}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}{|r|r|}
    \hline
    Number of Sensors & Messages per Second \\ \hline
                    1 &                7.55 \\ \hline
                    8 &               49.20 \\ \hline
  \end{tabular}
  \caption{Benchmark for Messages per Second from a Raspberry Pi to a \whitelist{NUC}}
  \label{tab:benchmark-nuc-raspberry-pi}
\end{table}

In \autoref{tab:benchmark-nuc-raspberry-pi}, we see the benchmark data for the \texttt{log-data}
function. For this benchmark, we set the \textit{Raspberry Pi} to not use any delay between
measurements. We also disabled the \texttt{CPU Load Aggregate} sensor, since this has an inherent
delay of one second due to the fact that it calculates the load average for a given duration. The
\textit{Raspberry Pi} application collects the data for all sensors in each iteration, which means
that we can actually get much more throughput with eight sensors than with a single sensor. Thus, we
can further conclude that the time to produce a measurement is negligible compared to the network
latency.

In order to test this theory, we decided to use parallel \texttt{curl} requests.

\begin{table}[H]
  \centering
  \begin{tabular}{|r|r|}
    \hline
    Number of concurrent Requests & Messages per Second \\ \hline
                                1 &                61.2 \\ \hline
                               10 &               239.0 \\ \hline
                               20 &               322.4 \\ \hline
                               50 &               379.5 \\ \hline
  \end{tabular}
  \caption{Benchmark for Messages per Second from a Desktop PC to a \whitelist{NUC}}
  \label{tab:benchmark-nuc-curl}
\end{table}

Each \texttt{curl} request in \autoref{tab:benchmark-nuc-curl} contains a single sensor record which
corresponds to the case in \autoref{tab:benchmark-nuc-raspberry-pi} with a single sensor. By looking
at this data, we can see that in the case of a single sensor, clearly the \textit{Raspberry Pi} is
the bottleneck, not the \textit{NUC}. It is safe to assume that the \textit{NUC} is able to handle
approximately 400 request per second.

Assuming that it is the case that a \textit{NUC} can handle 400 requests per second, we can deduce
that a \textit{NUC} is able to process streams from between

$\frac{400}{7.55} \times 1 \approx 53$

and

$\frac{400}{49.20} \times 8 \approx 65$

sensors.

This being a synthetic benchmark, it is likely that in a real world scenario, where sensor data is
sent only every \textit{x} seconds, the number of supported sensors is actually in the 100s instead
of only in the 10s.
