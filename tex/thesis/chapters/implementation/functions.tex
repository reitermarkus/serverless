\section{Functions}

With the OpenFaaS framework, every function consists of three parts: a function template, the
function's source code and a definition file.

Function templates are categorised by the programming language the corresponding function is written
in. At the bare minimum, a template contains a \texttt{Dockerfile} and a \texttt{template.yml}. The
\texttt{Dockerfile} has to be written in a way such that a \texttt{function} directory on the same
directory level is copied into the image. During the build step, this \texttt{function} directory
contains the source code, so depending on the programming language, it either has to be compiled or
moved to the correct location straight away. Additionally, the \texttt{Dockerfile} has to install
the \textit{OpenFaaS Watchdog}. The \textit{OpenFaaS Watchdog} is a service which is used to connect
the function to the \textit{OpenFaaS} gateway. Historically, the watchdog would pass requests to the
function via \textit{Standard Input} and return the function's \textit{Standard Output} as the
response. With this method however, the function could not control any aspect of the \textit{HTTP}
request and response. The new version of the \textit{OpenFaaS Watchdog} offers a few more operation
modes. The first, called \texttt{http}, forwards the received request to a specified port in the
function. This means that function templates using this mode have to be written in such a way that
they include a web server. This way the function can consume the \textit{HTTP} request directly,
which also makes calling functions easier since they can use standard \textit{HTTP} methods and
status codes. Another new mode is \texttt{static}, which can be used to create very simple functions
serving static files. \cite{of-watchdog} The \texttt{template.yml} file contains the metadata for
the function. This file can be empty, i.e. all metadata is optional, but most commonly it contains
at least the \texttt{language} property used to specify the programming language the template is
meant for. \cite{openfaas-build-functions} Commonly, a \texttt{function} directory containing a
“Hello, world!” function is included in the template itself to serve as a starting point when
creating a new function from scratch.

Another part needed for building a function is a definition file containing the name of the function
and all other data needed to deploy the functions. One essential part of this definition file is the
gateway URL, which the \textit{OpenFaaS Watchdog} uses to connect to the \textit{OpenFaaS} gateway.

\begin{code}[H]
  \centering
  \begin{lstlisting}[language=yaml]
version: 1.0
provider:
  name: openfaas
  gateway: http://127.0.0.1:8080
functions:
  filter:
    lang: rust-http
    handler: ./filter
    image: filter:latest
    environment:
      RUST_LOG: info
      write_debug: 'true'
      gateway_url: http://gateway:8080
  \end{lstlisting}
  \caption{A definition file for a Rust function called \texttt{filter}.}
  \label{code:function-definition}
\end{code}

In \autoref{code:function-definition} we can see that there are two different gateway URLs. The
first one, \texttt{provider.gateway}, is used by the \texttt{faas-cli} command line tool in order to
know where to deploy the function to. The second one, \\
\texttt{functions.filter.environment.gateway\_url} is the URL the gateway can be reached from inside
the cluster and the one passed to the \textit{OpenFaaS Watchdog}. Furthermore, the function template
is specified using \texttt{functions.filter.lang}, the path the function's source code is given by
\\
\texttt{functions.filter.handler} and the name of the \textit{Docker} image is specified by \\
\texttt{functions.filter.image}.

Assuming the definition file shown in \autoref{code:function-definition} is called
\texttt{filter.yml}, we can build the function using the following command:

\begin{lstlisting}[language=bash]
faas-cli build -f filter.yml
\end{lstlisting}

Once built, the function can be deployed using an equally simple command:

\begin{lstlisting}[language=bash]
faas-cli deploy -f filter.yml
\end{lstlisting}

We chose to write all of our functions in Rust. When we first started, there was not yet an official
\textit{OpenFaaS} function template for Rust, so we had to create our own. For our custom template -
\texttt{Dockerfile} -, we used the builder pattern. In our case this meant, that we would first
compile the Rust function using the official \textit{Docker} image for \textit{Rust}. This image is
based on \textit{Debian}, which means that we could then copy the compiled function into a bare
\textit{Debian} image which doesn't include the \textit{Rust} compiler, therefore saving space. This
resulted in each function image being around \SI{90}{\mega\byte} in size. Still, this was too much
for a simple function in our opinion.

It is possible to write a \texttt{Dockerfile} without using any base image, using the \texttt{FROM
scratch} directive. For this to work, however, we need to generate a statically compiled version of
our functions since there is no operating system providing libraries. By extension, this meant, that
we had to replace our compile step, since the official \texttt{Rust} docker image does not provide
support for creating statically linked binaries. Thankfully, there exists a \textit{Docker} image
called \texttt{rust-musl-builder} \cite{rust-musl-builder} for this exact reason. Using the
\texttt{rust-musl-builder} image, we could reduce the average image size for our functions to around
\SI{15}{\mega\byte}, a sixth of their original size.

\subsection{The \texttt{database} Function}

One of the core building blocks of our project is the database, which stores information about
devices and is used for persistently storing the data received from those devices. For this reason,
naturally we needed a function which allows us to interact with the database.

We used the \href{https://github.com/mongodb/mongo-rust-driver}{\texttt{mongodb-rust-driver}}, a
Rust library for interfacing with a MongoDB database. In order to reduce latency, OpenFaaS keeps
functions running for a specified amount of time before considering them unused and terminating
them. This means that we only need to establish a connection to our database once, when the function
container is first started. Since the initial startup is handled by the function template and not
the function handler, we used the
\href{https://github.com/rust-lang-nursery/lazy-static.rs}{\texttt{laze\_static}} to lazily
initialise a static variable holding our database connection.

The actual function handler first parses a \textit{JSON} request containing either an
\texttt{insert}, \texttt{insert\_or\_update}, \texttt{find}, \texttt{aggregate} or \texttt{update}
action. These actions are then converted from \texttt{JSON} to \texttt{BSON} (Binary JSON), the
format MongoDB and by extension the MongoDB Rust driver uses. This allows other functions to call
this function in order to interact with the database instead of duplicating this logic in every
function which needs to access the database.

\subsection{The \texttt{register-device} Function}

The \texttt{register-device} function is used, as the name implies, to register new devices. This
function is triggered when a new message is posted to the \\
\texttt{register-device} Kafka topic. The function handler parses the message, which must contain a
device ID and the device's name. If this is the case, it then calls the \texttt{database} function
in order to insert a new device or update an existing device's name.

\subsection{The \texttt{log-data} Function}

Similarly to the \texttt{register-device} function, the \texttt{log-data} function is triggered when
a new message is posted to the \texttt{log-data} topic. A message is expected to contain a device
ID, the data type (e.g. humidity, pressure, etc.), the time the data was recorded as well as the
data itself. After parsing the message in the correct format, the function validates that the data
type is contained in a list of supported types, otherwise it responds with \textit{400 Bad Request}
error code. Afterwards, the \texttt{database} function is called in order to add the data type to
the list of supported data types of the given device. Then, another call to the \texttt{database}
function is made to insert the data in the collection for the corresponding data type.

\subsection{The \texttt{devices} Function}

The \texttt{devices} is probably the simplest function in our project. It calls the
\texttt{database} function to retrieve a list of all registered devices and their corresponding data
types, converts the list from \textit{BSON} to \textit{JSON} and then returns it. It is used by the
\textit{UI} for displaying a list of all devices.

\subsection{The \texttt{filter} Function}

Another function that is used by the \textit{UI} is the filter function. Given a device ID, it
returns the logged data for a specified data type. The function supports calculating averages for a
specified number of time slices in a given interval. To do this, we call our \texttt{database}
function with the \texttt{aggregate} function. In the request, we send the \texttt{begin},
\texttt{end} and \texttt{interval}. The logic for splitting this time frame into equally long chunks
resides in the \texttt{database} function itself. To collect the averages for each part, we first
calculate the difference between \texttt{begin} and \texttt{end} and then calculate the
\texttt{step} by dividing the difference by \texttt{interval}. We then loop, starting from
\texttt{begin} until we reach \texttt{end}, incrementing by \texttt{step} in each iteration.

\begin{code}[H]
  \begin{lstlisting}[language=mongo]
'$match': {
  'time': {
    '$gte': ISODate('2020-02-26T18:23:00.000Z'),
    '$lte': ISODate('2020-02-26T21:53:00.000Z')
  }
}
  \end{lstlisting}
  \caption{A \textit{MongoDB} \texttt{\$match} statement filtering records with a \texttt{time}
  field containing a date between Feb. 26, 2020 18:23 and Feb. 26, 2020 21:53.}
  \label{code:mongodb-match}
\end{code}

As seen in \autoref{code:mongodb-match}, with \textit{MongoDB} it is very easy to retrieve records for a
given time span, using the \textit{\$match} pipeline operator.

\subsection{The \texttt{ui} Function}

Unlike many other functions, the \texttt{ui} function is not a \textit{Rust} function. Instead, it
utilises the new \textit{OpenFaaS Watchdog} mode called \texttt{static}. With it, we can create a
function solely consisting of static files. In the case of the \texttt{ui} function, these static
files are an \texttt{index.html}, a \texttt{style.css} and a \texttt{bundle.js}. Since our UI is
written purely in \textit{JavaScript}, we can use a single \texttt{webpack} command to produce all
these files. This process is explained in more detail in \autoref{sec:webpack}.

\subsection{The \texttt{tex-pdf} Function}

Like The \textit{ui} function, the \texttt{tex-pdf} function is also not a \textit{Rust} function.
This function is sort of a bonus, it is not required for the stack itself at all. \texttt{tex-pdf}
essentially queries the latest successful build from \textit{Azure}, tries to unpack the
\textit{PDF} in the \textit{thesis} artefact and finally display it in the browser. Therefore always
the latest version of the thesis will be served with the function and the user does not have to
compile the document with a \textit{LaTeX toolchain}.
