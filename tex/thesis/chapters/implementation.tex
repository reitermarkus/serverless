\section{Implementation}

Our task is to do \textit{IoT data analytics with serverless computing}, therefore as a first step
we started out by thinking about the underlying infrastructure. We decided on using Apache Kafka for
streaming, \textit{MongoDB} as our database and \textit{OpenFaaS} as the serverless platform.

The decision to use \textit{OpenFaaS} was made because of its ease to deploy a stack of services
using \textit{Docker Swarm}. While doing research we came across many different serverless
frameworks. \textit{OpenWhisk}, \textit{Fission} and \textit{Kubeless} just to name a few. While all
of those seem to have their benefits, none of them seemed to be as versatile as \textit{OpenFaaS}.
\textit{OpenFaaS} poses itself to have first class support for \textit{Docker Swarm} and being
\textit{Kubernetes} native. The former was particularly interesting for us as this meant that we
could test the framework without having to install any external tool except for  \textit{Docker}.
Running was as simple as cloning the \textit{OpenFaaS} repository, calling \texttt{docker swarm
init} and executing the provided initialisation script. Deploying an actual function is equally as
simple. One has the option to either deploy a function from the store through the nicely designed
\textit{OpenFaaS} gateway on port 8080 or with the preferred way, which is using the
\texttt{faas-cli}. Deploying a function from the store with it would look as follows

\begin{lstlisting}[language=bash]
$ faas store deploy figlet
\end{lstlisting}

where \texttt{figlet} is the name of the function in the store.

After gaining a grasp of how the platform works, we decided to put our own spin on it by firstly
modifying the given deploy script to our needs and porting it from \textit{Bash} to \textit{Rust}
for it to be cross platform. The next step then was to write our own configuration file for swarm
deployment, namely \texttt{deploy.yml}. This \textit{YAML} file includes the configuration for
\textit{Kafka}, \textit{Zookeeper}, \textit{MongoDB}, various services that are needed for
\textit{OpenFaaS}, a bunch of gateways for visualisation and the \textit{Kafka-Connector}. The
latter is particularly interesting, because its main purpose is to call a serverless function on a
Kafka topic change. To make a function react to a Kafka topic we can again use our example store
function \texttt{figlet}

\begin{lstlisting}[language=bash]
$ faas store deploy figlet --annotation topic="faas-request"
\end{lstlisting}

The deployment aspect is the same as before therefore the interesting part is the
\texttt{--annotation} flag, where \texttt{topic="faas-request"} is the \textit{Kafka} topic the
function is supposed to listen to and act on. We subsequently can look for the result in the logs of
the connector service.

While our technology stack for the most part was nice to work with, we still had our fair share of
problems. The most significant so far was in relation to our \textit{MongoDB} database.
\textit{MongoDB}'s API design is confusing to say the least. Questionable deprecation choices and
multiple connect interfaces are the most rampant examples. Unfortunately those were not the only
problems in that regard we ran into. Connecting through a node instance natively on the system would
work fine, however connecting through a deployed function in \textit{OpenFaaS} was not possible.
After applying various fixes the function was finally able to connect.

The next challenge will be to post to the database through the \textit{Kafka-Connector}. When that
is done we can finally focus on gathering data from IoT devices.

\newpage

\subsection{Functions}

With the OpenFaaS framework, every function consists of three parts: a function template, the
function's source code and a definition file.

Function templates are categorised by the programming language the corresponding function is written
in. At the bare minimum, a template contains a \texttt{Dockerfile} and a \texttt{template.yml}. The
\texttt{Dockerfile} has to be written in a way such that a \texttt{function} directory on the same
directory level is copied into the image. During the build step, this \texttt{function} directory
contains the source code, so depending on the programming language, it either has to be compiled or
moved to the correct location straight away. Additionally, the \texttt{Dockerfile} has to install
the \textit{OpenFaaS Watchdog}. The \textit{OpenFaaS Watchdog} is a service which is used to connect
the function to the \textit{OpenFaaS} gateway. Historically, the watchdog would pass requests to the
function via \textit{Standard Input} and the return the function's \textit{Standard Output} as the
response. With this method however, the function could not control any aspect of the \textit{HTTP}
request and response. The new version of the \textit{OpenFaaS Watchdog} offers a few more operation
modes. The first, called \texttt{http}, forwards the received request to a specified port in the
function. This means that function templates using this mode have to be written in such a way that
they include an web server. This way the function can consume the \textit{HTTP} request directly,
which also makes calling functions easier since they can use standard \textit{HTTP} methods and
status codes. Another new mode is \texttt{static}, which can be used to create very simple functions
serving static files. \cite{of-watchdog} The \texttt{template.yml} file contains the metadata for
the function. This file can be empty, i.e. all metadata is optional, but most commonly it contains
at least the \texttt{language} property used to specify the programming language the template is
meant for. \cite{openfaas-build-functions} Commonly, a \texttt{function} directory containing a
“Hello, world!” function is included in the template itself to serve as a starting point when
creating a new function from scratch.

Another part needed for building a function is a definition file containing the name of the function
and all other data needed to deploy the functions. One essential part of this definition file is the
gateway URL, which the \textit{OpenFaaS Watchdog} uses to connect to the \textit{OpenFaaS} gateway.

\begin{figure}[H]
  \begin{lstlisting}
version: 1.0
provider:
  name: openfaas
  gateway: http://127.0.0.1:8080
functions:
  filter:
    lang: rust-http
    handler: ./filter
    image: filter:latest
    environment:
      RUST_LOG: info
      write_debug: 'true'
      gateway_url: http://gateway:8080
  \end{lstlisting}
  \caption{A definition file for a Rust function called \texttt{filter}.}
  \label{fig:function-definition}
\end{figure}

In \autoref{fig:function-definition} we can see that there are two different gateway URLs. The
first one, \texttt{provider.gateway}, is used by the \texttt{faas-cli} command line tool in order to
know where to deploy the function to. The second one,
\texttt{functions.filter.environment.gateway\_url} is the URL the gateway can be reached from inside
the cluster and the one passed to the \textit{OpenFaaS Watchdog}. Furthermore, the function template
is specified using \texttt{functions.filter.lang}, the path the the function's source code is given
by \texttt{functions.filter.handler} and the name of the \textit{Docker} image is specified by
\texttt{functions.filter.image}.

Assuming the definition file shown in \autoref{fig:function-definition} is called
\texttt{filter.yml}, we can build the function using the following command:

\begin{lstlisting}[language=bash]
faas-cli build -f filter.yml
\end{lstlisting}

Once built, the function can be deployed using an equally simple command:

\begin{lstlisting}[language=bash]
faas-cli deploy -f filter.yml
\end{lstlisting}

\input{./chapters/implementation/mobile.tex}
\input{./chapters/implementation/serverless-stack.tex}
\input{./chapters/implementation/raspberry-pi.tex}
\input{./chapters/implementation/ui.tex}
\input{./chapters/implementation/azure.tex}
